# -*- coding: utf-8 -*-
"""Tanmay_paul_salary_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vKR7-bfy_YvxNHg8LNXj7q59WsodqMdL
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score

df = pd.read_csv("employee_salary_data.csv")
print(" Dataset Loaded Successfully!\n")
print(df.head())

print("\n Dataset Info:")
print(df.info())

print("\n Missing Values:")
print(df.isnull().sum())

print("\n Statistical Summary:")
print(df.describe())

print("\n Performing Exploratory Data Analysis (EDA)...")

plt.figure(figsize=(8,5))
sns.histplot(df['Salary'], bins=15, kde=True, color='skyblue')
plt.title("Salary Distribution")
plt.xlabel("Salary")
plt.ylabel("Count")
plt.show()

plt.figure(figsize=(8,5))
sns.boxplot(data=df, x="EducationLevel", y="Salary", palette="viridis")
plt.title("Salary by Education Level")
plt.show()

plt.figure(figsize=(10,6))
sns.barplot(data=df, x="Job Title", y="Salary", estimator=np.mean, palette="coolwarm")
plt.xticks(rotation=90)
plt.title("Average Salary by Job Title")
plt.show()

plt.figure(figsize=(8,5))
sns.scatterplot(data=df, x="YearsExperience", y="Salary", hue="EducationLevel", palette="Set2")
plt.title("Salary vs Years of Experience")
plt.show()

plt.figure(figsize=(8,5))
sns.scatterplot(data=df, x="Age", y="Salary", hue="Gender", palette="Set1")
plt.title("Age vs Salary by Gender")
plt.show()

temp_df = df.copy()
le = LabelEncoder()
for col in ["Job Title", "EducationLevel", "Location", "Gender"]:
    temp_df[col] = le.fit_transform(temp_df[col])

plt.figure(figsize=(8,6))
sns.heatmap(temp_df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Feature Correlation Heatmap")
plt.show()

le = LabelEncoder()
for col in ["Job Title", "EducationLevel", "Location", "Gender"]:
    df[col] = le.fit_transform(df[col])

X = df.drop("Salary", axis=1)
y = df["Salary"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("\n Simple Linear Regression (YearsExperience -> Salary)")

X_simple = df[["YearsExperience"]]
y_simple = df["Salary"]

X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_simple, y_simple, test_size=0.2, random_state=42)

lr_simple = LinearRegression()
lr_simple.fit(X_train_s, y_train_s)
y_pred_s = lr_simple.predict(X_test_s)

print("R¬≤ Score:", r2_score(y_test_s, y_pred_s))
print("MSE:", mean_squared_error(y_test_s, y_pred_s))

plt.scatter(X_test_s, y_test_s, color="blue", label="Actual")
plt.plot(X_test_s, y_pred_s, color="red", label="Predicted")
plt.xlabel("Years of Experience")
plt.ylabel("Salary")
plt.title("Simple Linear Regression")
plt.legend()
plt.show()

print("\n Multiple Linear Regression")

lr_multi = LinearRegression()
lr_multi.fit(X_train, y_train)
y_pred_multi = lr_multi.predict(X_test)

print("R¬≤ Score:", r2_score(y_test, y_pred_multi))
print("MSE:", mean_squared_error(y_test, y_pred_multi))

plt.figure(figsize=(6,5))
plt.scatter(y_test, y_pred_multi, color='green')
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
plt.title("Multiple Linear Regression: Actual vs Predicted")
plt.xlabel("Actual Salary")
plt.ylabel("Predicted Salary")
plt.show()

print("\n Polynomial Regression")

poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X_train_scaled)
X_test_poly = poly.transform(X_test_scaled)

poly_model = LinearRegression()
poly_model.fit(X_poly, y_train)
y_pred_poly = poly_model.predict(X_test_poly)

print("R¬≤ Score:", r2_score(y_test, y_pred_poly))
print("MSE:", mean_squared_error(y_test, y_pred_poly))

plt.figure(figsize=(6,5))
plt.scatter(y_test, y_pred_poly, color='orange')
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
plt.title("Polynomial Regression: Actual vs Predicted")
plt.xlabel("Actual Salary")
plt.ylabel("Predicted Salary")
plt.show()

print("\n Decision Tree Regression")

dt = DecisionTreeRegressor(random_state=42)
dt.fit(X_train, y_train)
y_pred_dt = dt.predict(X_test)

print("R¬≤ Score:", r2_score(y_test, y_pred_dt))
print("MSE:", mean_squared_error(y_test, y_pred_dt))

plt.figure(figsize=(6,5))
plt.scatter(y_test, y_pred_dt, color='purple')
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
plt.title("Decision Tree Regression: Actual vs Predicted")
plt.xlabel("Actual Salary")
plt.ylabel("Predicted Salary")
plt.show()

print("\n Random Forest Regression")

rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

print("R¬≤ Score:", r2_score(y_test, y_pred_rf))
print("MSE:", mean_squared_error(y_test, y_pred_rf))

plt.figure(figsize=(6,5))
plt.scatter(y_test, y_pred_rf, color='brown')
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
plt.title("Random Forest Regression: Actual vs Predicted")
plt.xlabel("Actual Salary")
plt.ylabel("Predicted Salary")
plt.show()

print("\n Support Vector Regression (SVR)")

svr = SVR(kernel='rbf')
svr.fit(X_train_scaled, y_train)
y_pred_svr = svr.predict(X_test_scaled)

print("R¬≤ Score:", r2_score(y_test, y_pred_svr))
print("MSE:", mean_squared_error(y_test, y_pred_svr))

plt.figure(figsize=(6,5))
plt.scatter(y_test, y_pred_svr, color='cyan')
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
plt.title("Support Vector Regression: Actual vs Predicted")
plt.xlabel("Actual Salary")
plt.ylabel("Predicted Salary")
plt.show()

models = {
    "Simple Linear Regression": r2_score(y_test_s, y_pred_s),
    "Multiple Linear Regression": r2_score(y_test, y_pred_multi),
    "Polynomial Regression": r2_score(y_test, y_pred_poly),
    "Decision Tree": r2_score(y_test, y_pred_dt),
    "Random Forest": r2_score(y_test, y_pred_rf),
    "Support Vector Regression": r2_score(y_test, y_pred_svr)
}

results = pd.DataFrame(list(models.items()), columns=["Model", "R2 Score"]).sort_values(by="R2 Score", ascending=False)
print("\nüèÅ Model Comparison:\n")
print(results)

plt.figure(figsize=(8,5))
sns.barplot(data=results, x="Model", y="R2 Score", palette="viridis")
plt.xticks(rotation=45)
plt.title("Model Performance Comparison")
plt.show()

plt.scatter(X_train_s['YearsExperience'], y_train_s, color='blue', label='Training data')
plt.plot(X_train_s['YearsExperience'], lr_simple.predict(X_train_s), color='red', label='Regression Line')
plt.title("Salary vs Experience (Training set)")
plt.xlabel("Years of Experience")
plt.ylabel("Salary")
plt.legend()
plt.show()

plt.scatter(X_test_s, y_test_s, color='green', label='Actual data')
plt.plot(X_test_s, y_pred_s, color='orange', label='Predicted line')
plt.title("Salary vs Experience (Test set)")
plt.xlabel("Years of Experience")
plt.ylabel("Salary")
plt.legend()
plt.show()

exp = float(input("Enter Years of Experience: "))
pred_salary = lr_simple.predict([[exp]])
print(f"\n Predicted Salary for {exp} years of experience: ‚Çπ{pred_salary[0]:.2f}")